<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>An analysis of weighted on-base averages using the ebnm package • ebnm</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="An analysis of weighted on-base averages using the ebnm package">
<meta property="og:description" content="ebnm">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">ebnm</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">1.1-20</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/stephenslab/ebnm" class="external-link">Source</a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>An analysis of weighted on-base averages using
the ebnm package</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/stephenslab/ebnm/blob/HEAD/vignettes/baseball.Rmd" class="external-link"><code>vignettes/baseball.Rmd</code></a></small>
      <div class="hidden name"><code>baseball.Rmd</code></div>

    </div>

    
    
<p>In this vignette, we illustrate the key features of
<strong>ebnm</strong> in an analysis of baseball statistics.</p>
<div class="section level2">
<h2 id="the-woba-data-set">The “wOBA” data set<a class="anchor" aria-label="anchor" href="#the-woba-data-set"></a>
</h2>
<p>We begin by loading and inspecting the <code>wOBA</code> data set,
which consists of wOBAs (“weighted on-base averages”) and standard
errors for the 2022 MLB regular season:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/stephenslab/ebnm" class="external-link">"ebnm"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"wOBA"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">)</span></span>
<span><span class="co"># [1] 688</span></span>
<span><span class="co">#   FanGraphsID           Name Team  PA     x     s</span></span>
<span><span class="co"># 1       19952     Khalil Lee  NYM   2 1.036 0.733</span></span>
<span><span class="co"># 2       16953 Chadwick Tromp  ATL   4 0.852 0.258</span></span>
<span><span class="co"># 3       19608     Otto Lopez  TOR  10 0.599 0.162</span></span>
<span><span class="co"># 4       24770   James Outman  LAD  16 0.584 0.151</span></span>
<span><span class="co"># 5        8090 Matt Carpenter  NYY 154 0.472 0.054</span></span>
<span><span class="co"># 6       15640    Aaron Judge  NYY 696 0.458 0.024</span></span></code></pre></div>
<p>Column “x” contains the observed wOBAs, which we interpret as
estimates of a player’s <em>hitting ability</em>. Column “s” gives
standard errors. (See below for background on the wOBA statistic and
details on how standard errors were calculated.)</p>
<p>The overall distribution of wOBAs appears as follows:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://ggplot2.tidyverse.org" class="external-link">"ggplot2"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">wOBA</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html" class="external-link">geom_histogram</a></span><span class="op">(</span>bins <span class="op">=</span> <span class="fl">64</span>, color <span class="op">=</span> <span class="st">"white"</span>,fill <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_classic</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="baseball_files/figure-html/woba-histogram-1.png" width="480" style="display: block; margin: auto;"></p>
<p>As the histogram shows, most players finished the season with a wOBA
between .200 and .400. A few had very high wOBAs (&gt;.500), while
others had wOBAs at or near zero. A casual inspection of the data
suggests that players with these extreme wOBAs were simply lucky (or
unlucky). For example, the 4 players with the highest wOBAs each had
fewer than 20 plate appearances. (The number of plate appearances, or
PAs, is the sample size over which wOBA is measured for each hitter, so
smaller numbers of PAs are generally associated with larger standard
errors.) It is unlikely that these players would have sustained their
high level of production over a full season’s worth of PAs!</p>
<p>In contrast, Aaron Judge’s production — which included a
record-breaking number of home runs — appears to be “real,” since it was
sustained over nearly 700 PAs. Other cases are more ambiguous: how, for
example, are we to assess Matt Carpenter, who had several exceptional
seasons between 2013 and 2018 but whose output steeply declined in
2019–2021 before his surprising “comeback” in 2022? An empirical Bayes
analysis can help to answer this and other questions.</p>
</div>
<div class="section level2">
<h2 id="the-ebnm-function">The “ebnm” function<a class="anchor" aria-label="anchor" href="#the-ebnm-function"></a>
</h2>
<p>Function <code><a href="../reference/ebnm.html">ebnm()</a></code> is the main interface for fitting the
empirical Bayes normal means model; it is a “Swiss army knife” that
allows for various choices of prior family <span class="math inline">\(\mathcal{G}\)</span> as well as providing multiple
options for fitting and tuning models. For example, we can fit a normal
means model with <span class="math inline">\(\mathcal{G}\)</span> taken
to be the family of normal distributions as follows:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">wOBA</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">s</span> <span class="op">&lt;-</span> <span class="va">wOBA</span><span class="op">$</span><span class="va">s</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">wOBA</span><span class="op">$</span><span class="va">Name</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">s</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">wOBA</span><span class="op">$</span><span class="va">Name</span></span>
<span><span class="va">fit_normal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm.html">ebnm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, prior_family <span class="op">=</span> <span class="st">"normal"</span>, mode <span class="op">=</span> <span class="st">"estimate"</span><span class="op">)</span></span></code></pre></div>
<p>(The default behavior is to fix the prior mode at zero. Since we
certainly do not expect the distribution of true hitting ability to have
a mode at zero, we set <code>mode = "estimate"</code>.)</p>
<p>The <code>ebnm</code> package has a second model-fitting interface in
which each prior family gets its own function:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_normal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_normal.html">ebnm_normal</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, mode <span class="op">=</span> <span class="st">"estimate"</span><span class="op">)</span></span></code></pre></div>
<p>Textual and graphical overviews of results can be obtained using the
<code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> and <code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> methods. The
<code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> method appears as follows:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># Call:</span></span>
<span><span class="co"># ebnm_normal(x = x, s = s, mode = "estimate")</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># EBNM model was fitted to 688 observations with _heteroskedastic_ standard errors.</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># The fitted prior belongs to the _normal_ prior family.</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># 2 degrees of freedom were used to estimate the model.</span></span>
<span><span class="co"># The log likelihood is 989.64.</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># Available posterior summaries: _mean_, _sd_.</span></span>
<span><span class="co"># Use method fitted() to access available summaries.</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># A posterior sampler is _not_ available.</span></span>
<span><span class="co"># One can be added via function ebnm_add_sampler().</span></span></code></pre></div>
<p>The <code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> method visualizes results, comparing the
“observed” values <span class="math inline">\(x_i\)</span> (the initial
wOBA estimates) against the empirical Bayes posterior mean estimates
<span class="math inline">\(\hat{\theta}_i\)</span>:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span></span></code></pre></div>
<p><img src="baseball_files/figure-html/plot-ebnm-normal-1.png" width="372" style="display: block; margin: auto;"></p>
<p>The dashed line shows the diagonal <span class="math inline">\(x =
y\)</span>, which makes shrinkage effects clearly visible. In
particular, the most extreme wOBAs on either end of the spectrum are
strongly shrunk towards the league average (around .300).</p>
<p>Since the <code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> method returns a “ggplot” object <span class="citation">(Wickham 2016)</span>, the plot can be conveniently
customized using <code>ggplot2</code>. For example, we can vary the
color of points by the number of plate appearances:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">$</span><span class="va">PA</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"wOBA"</span>, y <span class="op">=</span> <span class="st">"EB estimate of true wOBA skill"</span>, </span>
<span>       color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">PA</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_gradient.html" class="external-link">scale_color_gradient</a></span><span class="op">(</span>low <span class="op">=</span> <span class="st">"blue"</span>, high <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code></pre></div>
<p><img src="baseball_files/figure-html/plot-ebnm-normal-better-1.png" width="444" style="display: block; margin: auto;"></p>
<p>The plot tells us that wOBAs associated with fewer plate appearances
(blue points) were shrunk toward the league average much more strongly
than wOBAs for hitters with many plate appearances (red points).</p>
<p>Let us revisit the first 6 hitters in the data set to see what the
EBNM model suggests about their true hitting ability. The method returns
a posterior summary for each hitter (by default, the posterior mean and
standard deviation):</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#                 mean     sd</span></span>
<span><span class="co"># Khalil Lee     0.303 0.0287</span></span>
<span><span class="co"># Chadwick Tromp 0.308 0.0286</span></span>
<span><span class="co"># Otto Lopez     0.310 0.0283</span></span>
<span><span class="co"># James Outman   0.311 0.0282</span></span>
<span><span class="co"># Matt Carpenter 0.339 0.0254</span></span>
<span><span class="co"># Aaron Judge    0.394 0.0184</span></span></code></pre></div>
<p>Estimates for the first four ballplayers are shrunk strongly toward
the league average, reflecting the fact that these players had very few
plate appearances. Carpenter had many more plate appearances (154) than
these other four players, but according to this model we should remain
skeptical about his strong performance; after factoring in the prior, we
judge his “true”’’” talent to be much closer to the league average,
downgrading an observed wOBA of .472 to the posterior mean estimate of
.339.</p>
</div>
<div class="section level2">
<h2 id="comparing-different-priors">Comparing different priors<a class="anchor" aria-label="anchor" href="#comparing-different-priors"></a>
</h2>
<p>Judge’s “true” talent is also estimated to be much lower (.394) than
his observed wOBA (.458) despite sustaining this high level of
production over a full season (696 PAs). For this reason, one might ask
whether a prior that is more flexible than the normal prior — that is, a
prior that can better adapt to “outliers” like Judge — might produce a
different result. The <strong>ebnm</strong> package is very well suited
to answering this question. For example, to obtain results using the
family of all unimodal priors rather than a normal prior, we need only
update the argument to <code>prior_family</code>:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_unimodal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm.html">ebnm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, prior_family <span class="op">=</span> <span class="st">"unimodal"</span>, mode <span class="op">=</span> <span class="st">"estimate"</span><span class="op">)</span></span></code></pre></div>
<p>It is straightforward to produce a side-by-side visualization of the
fitted models simply by including both models as arguments to the
<code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> method. We also use the <code>subset</code> argument
to focus on the results for Judge and other players with the most plate
appearances:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">top50</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/order.html" class="external-link">order</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">$</span><span class="va">PA</span>, decreasing <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">top50</span> <span class="op">&lt;-</span> <span class="va">top50</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">50</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span>, <span class="va">fit_unimodal</span>, subset <span class="op">=</span> <span class="va">top50</span><span class="op">)</span></span></code></pre></div>
<p><img src="baseball_files/figure-html/ebnm-normal-vs-unimodal-1.png" width="540" style="display: block; margin: auto;"></p>
<p>This plot illustrates the ability of the unimodal prior to better
adapt to the data: estimates for players with many plate appearances and
outlying performances (very high or very low wOBAs) are not adjusted
quite so strongly toward the league average. Judge’s estimated “true”
talent, for example, remains much closer to his observed wOBA:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"PA"</span>,<span class="st">"x"</span><span class="op">)</span><span class="op">]</span>,</span>
<span>             <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span>,</span>
<span>             <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit_unimodal</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"PA"</span>, <span class="st">"x"</span>, <span class="st">"mean_n"</span>, <span class="st">"sd_n"</span>, <span class="st">"mean_u"</span>, <span class="st">"sd_u"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#                 PA     x mean_n   sd_n mean_u   sd_u</span></span>
<span><span class="co"># Khalil Lee       2 1.036  0.303 0.0287  0.302 0.0277</span></span>
<span><span class="co"># Chadwick Tromp   4 0.852  0.308 0.0286  0.307 0.0306</span></span>
<span><span class="co"># Otto Lopez      10 0.599  0.310 0.0283  0.310 0.0315</span></span>
<span><span class="co"># James Outman    16 0.584  0.311 0.0282  0.311 0.0318</span></span>
<span><span class="co"># Matt Carpenter 154 0.472  0.339 0.0254  0.355 0.0430</span></span>
<span><span class="co"># Aaron Judge    696 0.458  0.394 0.0184  0.439 0.0155</span></span></code></pre></div>
<p>Carpenter’s estimated “true” talent is also higher, but is still
adjusted much more than Judge’s in light of Carpenter’s smaller sample
size. Interestingly, the unimodal prior also assigns greater uncertainty
(the ``sd_u’’ column) to Carpenter’s estimate than does the normal
prior.</p>
<p>Recall that the two normal means models differ only in the priors
used, so we can understand the differences in the shrinkage behavior of
these models by inspecting the priors. Calling <code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> with
<code>incl_cdf = TRUE</code> shows the cumulative distribution functions
(CDFs) of the fitted priors <span class="math inline">\(\hat{g}\)</span>. Since we are particularly
interested in understanding the differences in shrinkage behavior for
large wOBAs such as Judge’s, we create a second plot that zooms in on
the interval between .350 and .450:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://wilkelab.org/cowplot/" class="external-link">"cowplot"</a></span><span class="op">)</span></span>
<span><span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span>, <span class="va">fit_unimodal</span>, incl_cdf <span class="op">=</span> <span class="cn">TRUE</span>, incl_pm <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html" class="external-link">xlim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">.250</span>, <span class="fl">.350</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/guides.html" class="external-link">guides</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span></span>
<span><span class="va">p2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span>, <span class="va">fit_unimodal</span>, incl_cdf <span class="op">=</span> <span class="cn">TRUE</span>, incl_pm <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html" class="external-link">lims</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">.350</span>, <span class="fl">.450</span><span class="op">)</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.95</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://wilkelab.org/cowplot/reference/plot_grid.html" class="external-link">plot_grid</a></span><span class="op">(</span><span class="va">p1</span>, <span class="va">p2</span>, nrow <span class="op">=</span> <span class="fl">1</span>, ncol <span class="op">=</span> <span class="fl">2</span>, rel_widths <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="baseball_files/figure-html/ebnm-normal-vs-unimodal-3-1.png" width="780" style="display: block; margin: auto;"></p>
<p>The plot on the right shows that the fitted normal prior has almost
no mass above .400, explaining why Judge’s estimate is shrunk so
strongly toward the league average, whereas the unimodal prior is
flexible enough to permit posterior estimates above .400.</p>
<p>The posterior means and standard errors returned from the
<code><a href="../reference/ebnm.html">ebnm()</a></code> call cannot be used to obtain credible intervals
(except for the special case of the normal prior). Therefore, we provide
additional methods <code><a href="https://rdrr.io/r/stats/quantile.html" class="external-link">quantile()</a></code> and <code><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint()</a></code>,
which return, respectively, posterior quantiles and posterior credible
intervals, defined as the narrowest <em>continuous</em> intervals <span class="math inline">\([a_i, b_i]\)</span> such that the “true mean”
<span class="math inline">\(\theta_i\)</span> is in <span class="math inline">\([a_i, b_i]\)</span> with posterior probability at
least <span class="math inline">\(1 - \alpha\)</span>, where <span class="math inline">\(\alpha \in (0, 1)\)</span>. Both methods are
implemented using Monte Carlo techniques, which can be slow for large
data sets, so credible intervals are not computed by default.<br>
We add a Monte Carlo sampler using function
<code><a href="../reference/ebnm_add_sampler.html">ebnm_add_sampler()</a></code>; alternatively, we could have added a
sampler in our initial calls to <code><a href="../reference/ebnm.html">ebnm()</a></code> by specifying
<code>output = output_all()</code>. We then compute, 80% credible
intervals for the EBNM model with unimodal prior, setting a seed for
reproducibility:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_unimodal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_add_sampler.html">ebnm_add_sampler</a></span><span class="op">(</span><span class="va">fit_unimodal</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit_unimodal</span>, level <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#                CI.lower CI.upper</span></span>
<span><span class="co"># Khalil Lee        0.277    0.328</span></span>
<span><span class="co"># Chadwick Tromp    0.277    0.334</span></span>
<span><span class="co"># Otto Lopez        0.277    0.336</span></span>
<span><span class="co"># James Outman      0.277    0.335</span></span>
<span><span class="co"># Matt Carpenter    0.277    0.389</span></span>
<span><span class="co"># Aaron Judge       0.428    0.458</span></span></code></pre></div>
<p>Interestingly, the 80% credible interval for Carpenter is very wide,
and shares the same lower bound as the first four ballplayers (who,
recall, have very few plate appearances).</p>
</div>
<div class="section level2">
<h2 id="reanalyzing-the-data-using-a-nonparametric-prior">Reanalyzing the data using a nonparametric prior<a class="anchor" aria-label="anchor" href="#reanalyzing-the-data-using-a-nonparametric-prior"></a>
</h2>
<p>Above, we demonstrated how the <code>ebnm</code> package makes it is
easy to perform EBNM analyses with different types of priors, then
compared results across two different choices of prior family. Each of
these families makes different assumptions about the data which, <em>a
priori</em>, may be more or less plausible. An alternative to prior
families that make specific assumptions about the data is to use the
prior family that contains <em>all</em> distributions <span class="math inline">\(\mathcal{G}_{\mathrm{npmle}}\)</span>, which is in
a sense “assumption free.” Note that although nonparametric priors
require specialized computational techniques, switching to a
nonparametric prior is seamless in <strong>ebnm</strong>, as these
implementation details are hidden. Similar to above, we need only make a
single change to the <code>prior_family</code> argument:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_npmle</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm.html">ebnm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, prior_family <span class="op">=</span> <span class="st">"npmle"</span><span class="op">)</span></span></code></pre></div>
<p>(Note that because the family <span class="math inline">\(\mathcal{G}_{\mathrm{npmle}}\)</span> is not
unimodal, the <code>mode = "estimate"</code> option is not relevant
here.)</p>
<p>Although the implementation details are hidden by default, it can
sometimes be helpful to see what is going on “behind the scenes,”
particularly for flagging or diagnosing issues. By default, ebnm uses
the mixsqp package <span class="citation">(Kim et al. 2020)</span> to
fit the NPMLE <span class="math inline">\(\hat{g} \in
\mathcal{G}_{\mathrm{npmle}}\)</span>. We can monitor convergence of the
mix-SQP optimization algorithm by setting the <code>verbose</code>
control argument to <code>TRUE</code>:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_npmle</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm.html">ebnm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, prior_family <span class="op">=</span> <span class="st">"npmle"</span>, </span>
<span>                  control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Running mix-SQP algorithm 0.3-54 on 688 x 95 matrix</span></span>
<span><span class="co"># convergence tol. (SQP):     1.0e-08</span></span>
<span><span class="co"># conv. tol. (active-set):    1.0e-10</span></span>
<span><span class="co"># zero threshold (solution):  1.0e-08</span></span>
<span><span class="co"># zero thresh. (search dir.): 1.0e-14</span></span>
<span><span class="co"># l.s. sufficient decrease:   1.0e-02</span></span>
<span><span class="co"># step size reduction factor: 7.5e-01</span></span>
<span><span class="co"># minimum step size:          1.0e-08</span></span>
<span><span class="co"># max. iter (SQP):            1000</span></span>
<span><span class="co"># max. iter (active-set):     20</span></span>
<span><span class="co"># number of EM iterations:    10</span></span>
<span><span class="co"># Computing SVD of 688 x 95 matrix.</span></span>
<span><span class="co"># Matrix is not low-rank; falling back to full matrix.</span></span>
<span><span class="co"># iter        objective max(rdual) nnz stepsize max.diff nqp nls</span></span>
<span><span class="co">#    1 +9.583407733e-01  -- EM --   95 1.00e+00 6.08e-02  --  --</span></span>
<span><span class="co">#    2 +8.298700300e-01  -- EM --   95 1.00e+00 2.87e-02  --  --</span></span>
<span><span class="co">#    3 +7.955308369e-01  -- EM --   95 1.00e+00 1.60e-02  --  --</span></span>
<span><span class="co">#    4 +7.819858634e-01  -- EM --   68 1.00e+00 1.05e-02  --  --</span></span>
<span><span class="co">#    5 +7.753787534e-01  -- EM --   53 1.00e+00 7.57e-03  --  --</span></span>
<span><span class="co">#    6 +7.717040208e-01  -- EM --   49 1.00e+00 5.73e-03  --  --</span></span>
<span><span class="co">#    7 +7.694760705e-01  -- EM --   47 1.00e+00 4.48e-03  --  --</span></span>
<span><span class="co">#    8 +7.680398878e-01  -- EM --   47 1.00e+00 3.58e-03  --  --</span></span>
<span><span class="co">#    9 +7.670690681e-01  -- EM --   44 1.00e+00 2.91e-03  --  --</span></span>
<span><span class="co">#   10 +7.663865515e-01  -- EM --   42 1.00e+00 2.40e-03  --  --</span></span>
<span><span class="co">#    1 +7.658902386e-01 +6.493e-02  39  ------   ------   --  --</span></span>
<span><span class="co">#    2 +7.655114904e-01 +5.285e-02  19 1.00e+00 9.88e-02  20   1</span></span>
<span><span class="co">#    3 +7.627839841e-01 +1.411e-02   7 1.00e+00 1.28e-01  20   1</span></span>
<span><span class="co">#    4 +7.626270875e-01 +2.494e-04   7 1.00e+00 3.23e-01   8   1</span></span>
<span><span class="co">#    5 +7.626270755e-01 +1.748e-08   7 1.00e+00 4.94e-04   2   1</span></span>
<span><span class="co">#    6 +7.626270755e-01 -2.796e-08   7 1.00e+00 2.76e-07   2   1</span></span>
<span><span class="co"># Optimization took 0.03 seconds.</span></span>
<span><span class="co"># Convergence criteria met---optimal solution found.</span></span></code></pre></div>
<p>This output shows no issues with convergence of the optimization
algorithm; the mix-SQP algorithm converged to the solution (up to
numerical rounding error) in only 6 iterations (not counting the 10
initial EM iterations). In some cases, convergence issues can arise when
fitting nonparametric models to large or complex data sets, and
revealing the details of the optimization can help to pinpoint these
issues.</p>
<p>Let us visually compare the three fits obtained so far:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span>, <span class="va">fit_unimodal</span>, <span class="va">fit_npmle</span>, incl_cdf <span class="op">=</span> <span class="cn">TRUE</span>, subset <span class="op">=</span> <span class="va">top50</span><span class="op">)</span></span></code></pre></div>
<p><img src="baseball_files/figure-html/plot-npmle-1.png" width="510" style="display: block; margin: auto;"><img src="baseball_files/figure-html/plot-npmle-2.png" width="510" style="display: block; margin: auto;"></p>
<p>As before, estimates largely agree, differing primarily at the tails.
Both the unimodal prior family and the NPMLE are sufficiently flexible
to avoid the strong shrinkage behavior of the normal prior family.</p>
<p>Fits can be compared quantitatively using the <code><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik()</a></code>
method, which, in addition to the log likelihood for each model,
usefully reports the number of free parameters (i.e., degrees of
freedom):</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">fit_unimodal</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">fit_npmle</span><span class="op">)</span></span>
<span><span class="co"># 'log Lik.' 992.6578 (df=40)</span></span>
<span><span class="co"># 'log Lik.' 994.193 (df=94)</span></span></code></pre></div>
<p>A nonparametric prior <span class="math inline">\(\mathcal{G}\)</span> is approximated by <span class="math inline">\(K\)</span> mixture components on a fixed grid,
with mixture proportions to be estimated. We can infer from the above
output that the family of unimodal priors has been approximated by a
family of mixtures over <span class="math inline">\(K = 41\)</span>
fixed components, while <span class="math inline">\(\mathcal{G}_\text{npmle}\)</span> has been
approximated as a family of mixtures over a grid of <span class="math inline">\(K = 95\)</span> point masses spanning the range of
the data. (The number of degrees of freedom is one fewer than <span class="math inline">\(K\)</span> because the mixture proportions must
always sum to 1, which removes one degree of freedom from the estimation
of <span class="math inline">\({\boldsymbol{\pi}}\)</span>.)</p>
<p>The default behaviour for nonparametric prior families is to choose
<span class="math inline">\(K\)</span> such that the likelihood obtained
using estimate <span class="math inline">\(\hat{g}\)</span> should be
(on average) within one log-likelihood unit of the optimal estimate from
among the entire nonparametric family <span class="math inline">\(\mathcal{G}\)</span> <span class="citation">(see
Willwerscheid 2021)</span>. Thus, a finer approximating grid should not
yield a large improvement in the log-likelihood. We can check this by
using <code><a href="../reference/ebnm_scale_npmle.html">ebnm_scale_npmle()</a></code> to create a finer grid:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">scale_npmle</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_scale_npmle.html">ebnm_scale_npmle</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, KLdiv_target <span class="op">=</span> <span class="fl">0.001</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, </span>
<span>                                max_K <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">fit_npmle_finer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_npmle.html">ebnm_npmle</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, scale <span class="op">=</span> <span class="va">scale_npmle</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">fit_npmle</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">fit_npmle_finer</span><span class="op">)</span></span>
<span><span class="co"># 'log Lik.' 994.193 (df=94)</span></span>
<span><span class="co"># 'log Lik.' 994.2504 (df=528)</span></span></code></pre></div>
<p>As the theory predicts, a much finer grid, with <span class="math inline">\(K = 529\)</span>, results in only a modest
improvement in the log-likelihood. <strong>ebnm</strong> provides
similar functions <code><a href="../reference/ebnm_scale_unimix.html">ebnm_scale_unimix()</a></code> and
<code><a href="../reference/ebnm_scale_normalmix.html">ebnm_scale_normalmix()</a></code> to customize grids for,
respectively, unimodal and normal scale mixture prior families.</p>
<p>One potential issue with the NPMLE is that, since it is discrete (as
the above CDF plot makes apparent), observations are variously shrunk
toward one of the support points, which can result in poor interval
estimates. For illustration, we calculate 80% intervals using 10% and
90% quantiles (note that this is not the same as using the
<code><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint()</a></code> method with <code>level = 0.8</code>, since
<code><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint()</a></code> returns the <em>narrowest</em> continuous
intervals covering 80% of the posterior probability):</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_npmle</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_add_sampler.html">ebnm_add_sampler</a></span><span class="op">(</span><span class="va">fit_npmle</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/quantile.html" class="external-link">quantile</a></span><span class="op">(</span><span class="va">fit_npmle</span>, probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.9</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#                  10%   90%</span></span>
<span><span class="co"># Khalil Lee     0.276 0.342</span></span>
<span><span class="co"># Chadwick Tromp 0.276 0.342</span></span>
<span><span class="co"># Otto Lopez     0.276 0.342</span></span>
<span><span class="co"># James Outman   0.276 0.342</span></span>
<span><span class="co"># Matt Carpenter 0.309 0.430</span></span>
<span><span class="co"># Aaron Judge    0.419 0.430</span></span></code></pre></div>
<p>Each interval endpoint is constrained to lie at one of the support
points of the NPMLE <span class="math inline">\(\hat{g}\)</span>. The
interval estimate for Judge strikes us as far too narrow. Indeed, the
NPMLE can sometimes yield degenerate interval estimates:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit_npmle</span>, level <span class="op">=</span> <span class="fl">0.8</span>, parm <span class="op">=</span> <span class="st">"Aaron Judge"</span><span class="op">)</span></span>
<span><span class="co">#              CI.lower  CI.upper</span></span>
<span><span class="co"># Aaron Judge 0.4298298 0.4298298</span></span></code></pre></div>
<p>To address this and other issues, the <strong>deconvolveR</strong>
package <span class="citation">(Narasimhan and Efron 2020)</span> uses a
penalized likelihood that encourages “smooth” priors <span class="math inline">\(\hat{g}\)</span>; that is, priors <span class="math inline">\(\hat{g}\)</span> for which few of the mixture
proportions are zero:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_deconv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_deconvolver.html">ebnm_deconvolver</a></span><span class="op">(</span><span class="va">x</span> <span class="op">/</span> <span class="va">s</span>, output <span class="op">=</span> <span class="fu"><a href="../reference/ebnm.html">ebnm_output_all</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_deconv</span>, incl_cdf <span class="op">=</span> <span class="cn">TRUE</span>, incl_pm <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p><img src="baseball_files/figure-html/ebnm-deconvolver-1.png" width="300" style="display: block; margin: auto;"></p>
<p>Note however that since package <strong>deconvolveR</strong> fits a
model to <span class="math inline">\(z\)</span>-scores rather than
observations and associated standard errors, the “true” means <span class="math inline">\(\theta\)</span> being estimated are <span class="math inline">\(z\)</span>-scores rather than raw wOBA skill.
While this may be<br>
reasonable in many settings, it does not seem appropriate for the wOBA
data:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit_deconv</span>, level <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">*</span> <span class="va">s</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#                CI.lower CI.upper</span></span>
<span><span class="co"># Khalil Lee        0.000    1.600</span></span>
<span><span class="co"># Chadwick Tromp    0.563    1.127</span></span>
<span><span class="co"># Otto Lopez        0.442    0.796</span></span>
<span><span class="co"># James Outman      0.412    0.742</span></span>
<span><span class="co"># Matt Carpenter    0.413    0.531</span></span>
<span><span class="co"># Aaron Judge       0.406    0.459</span></span></code></pre></div>
<p>These interval estimates do not match our basic intuitions; for
example, a wOBA over .600 has never been sustained over a full
season.</p>
</div>
<div class="section level2">
<h2 id="background-on-the-weighted-on-base-average">Background on the “weighted on-base average”<a class="anchor" aria-label="anchor" href="#background-on-the-weighted-on-base-average"></a>
</h2>
<p>A longstanding tradition in empirical Bayes research is to include an
analysis of batting averages using data from Major League Baseball; see,
for example, <span class="citation">Brown (2008)</span>; <span class="citation">Jiang and Zhang (2010)</span>; <span class="citation">Gu and Koenker (2017)</span>. Until recently, batting
averages were the most important measurement of a hitter’s performance,
with the prestigious yearly “batting title” going to the hitter with the
highest average. However, with the rise of baseball analytics, metrics
that better correlate to teams’ overall run production have become
increasingly preferred. One such metric is wOBA (“weighted on-base
average”), which is both an excellent measure of a hitter’s offensive
production and, unlike competing metrics such as MLB’s xwOBA <span class="citation">(Sharpe 2019)</span> or Baseball Prospectus’s DRC+
<span class="citation">(Judge 2019)</span>, can be calculated using
publicly available data and methods.</p>
<p>Initially proposed by <span class="citation">Tango, Lichtman, and
Dolphin (2006)</span>, wOBA assigns values (“weights”) to hitting
outcomes according to how much the outcome contributes on average to run
production. For example, while batting average treats singles
identically to home runs, wOBA gives a hitter more than twice as much
credit for a home run. (Note that weights are updated from year to year,
but wOBA weights for singles have remained near 0.9 for the last several
decades, while weights for home runs have hovered around 2.0; see <span class="citation">FanGraphs (2023)</span>.)</p>
<p>Given a vector of wOBA weights <span class="math inline">\(\mathbf{w}\)</span>, hitter <span class="math inline">\(i\)</span>’s wOBA is the weighted average <span class="math display">\[
x_i = \mathbf{w}^\top \mathbf{z}^{(i)} / n_i,
\]</span> where <span class="math inline">\(\mathbf{z}^{(i)} =
(z_1^{(i)}, \ldots, z_7^{(i)})\)</span> tallies outcomes (singles,
doubles, triples, home runs, walks, hit-by-pitches and outs) over the
hitter’s <span class="math inline">\(n_i\)</span> plate appearances
(PAs). Modeling hitting outcomes as i.i.d. <span class="math display">\[
\mathbf{z}^{(i)} \sim \text{Multinomial}(n_i, \mathbf{\pi}^{(i)}),
\]</span> where <span class="math inline">\(\mathbf{\pi}^{(i)} = (\pi_1,
\ldots, \pi_7^{(i)})\)</span> is the vector of “true” outcome
probabilities for hitter <span class="math inline">\(i\)</span>, we can
regard <span class="math inline">\(x_i\)</span> as a point estimate for
the hitter’s “true wOBA skill”, <span class="math display">\[
\theta_i = \mathbf{w}^\top \mathbf{\pi}^{(i)}.
\]</span> Standard errors for the <span class="math inline">\(x_i\)</span>’s can be estimated as <span class="math display">\[
s_i^2 = \mathbf{w}^\top \hat{\mathbf{\Sigma}}^{(i)} \mathbf{w}/n_i,
\]</span> where <span class="math inline">\(\hat{\mathbf{\Sigma}}^{(i)}\)</span> is the
estimate of the covariance matrix for the multinomial model obtained by
setting <span class="math inline">\(\mathbf{\pi} =
\hat{\mathbf{\pi}}\)</span>, where <span class="math display">\[
\hat{\mathbf{\pi}}^{(i)} = \mathbf{z}^{(i)}/n_i.
\]</span> (To deal with small sample sizes, we conservatively lower
bound each standard error by the standard error that would be obtained
by plugging in league-average event probabilities <span class="math inline">\(\hat{\mathbf{\pi}}_{\mathrm{lg}} = \sum_{i=1}^N
\mathbf{z}^{(i)}/ \sum_{i=1}^N n_i\)</span>, where <span class="math inline">\(N\)</span> is the number of hitters in the data
set.)</p>
<p>The relative complexity of wOBA makes it well suited for analysis via
<strong>ebnm</strong>. With batting average, a common approach is to
obtain empirical Bayes estimates using a beta-binomial model (see, for
example, <span class="citation">Robinson (2017)</span>). With wOBA, one
can estimate hitting outcome probabilities by way of a
Dirichlet-multinomial model; alternatively, one can approximate the
likelihood as normal and fit an EBNM model directly to the observed
wOBAs. We take the latter approach.</p>
</div>
<div class="section level2">
<h2 id="session-information">Session information<a class="anchor" aria-label="anchor" href="#session-information"></a>
</h2>
<p>The following R version and packages were used to generate this
vignette:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html" class="external-link">sessionInfo</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co"># R version 4.3.2 (2023-10-31)</span></span>
<span><span class="co"># Platform: aarch64-apple-darwin20 (64-bit)</span></span>
<span><span class="co"># Running under: macOS Monterey 12.3</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># Matrix products: default</span></span>
<span><span class="co"># BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib </span></span>
<span><span class="co"># LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># locale:</span></span>
<span><span class="co"># [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># time zone: America/New_York</span></span>
<span><span class="co"># tzcode source: internal</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># attached base packages:</span></span>
<span><span class="co"># [1] stats     graphics  grDevices utils     datasets  methods   base     </span></span>
<span><span class="co"># </span></span>
<span><span class="co"># other attached packages:</span></span>
<span><span class="co"># [1] cowplot_1.1.3 ggplot2_3.4.4 ebnm_1.1-20  </span></span>
<span><span class="co"># </span></span>
<span><span class="co"># loaded via a namespace (and not attached):</span></span>
<span><span class="co">#  [1] sass_0.4.8         utf8_1.2.4         generics_0.1.3     ashr_2.2-63       </span></span>
<span><span class="co">#  [5] stringi_1.8.3      lattice_0.21-9     digest_0.6.34      magrittr_2.0.3    </span></span>
<span><span class="co">#  [9] RColorBrewer_1.1-3 evaluate_0.23      grid_4.3.2         fastmap_1.1.1     </span></span>
<span><span class="co"># [13] jsonlite_1.8.8     Matrix_1.6-1.1     mixsqp_0.3-54      purrr_1.0.2       </span></span>
<span><span class="co"># [17] fansi_1.0.6        scales_1.3.0       truncnorm_1.0-9    invgamma_1.1      </span></span>
<span><span class="co"># [21] textshaping_0.3.7  jquerylib_0.1.4    cli_3.6.2          rlang_1.1.3       </span></span>
<span><span class="co"># [25] deconvolveR_1.2-1  munsell_0.5.0      splines_4.3.2      withr_2.5.2       </span></span>
<span><span class="co"># [29] cachem_1.0.8       yaml_2.3.8         tools_4.3.2        SQUAREM_2021.1    </span></span>
<span><span class="co"># [33] memoise_2.0.1      dplyr_1.1.4        colorspace_2.1-0   vctrs_0.6.5       </span></span>
<span><span class="co"># [37] R6_2.5.1           lifecycle_1.0.4    stringr_1.5.1      fs_1.6.3          </span></span>
<span><span class="co"># [41] trust_0.1-8        ragg_1.2.7         irlba_2.3.5.1      pkgconfig_2.0.3   </span></span>
<span><span class="co"># [45] desc_1.4.3         pkgdown_2.0.7      bslib_0.6.1        pillar_1.9.0      </span></span>
<span><span class="co"># [49] gtable_0.3.4       glue_1.7.0         Rcpp_1.0.12        systemfonts_1.0.5 </span></span>
<span><span class="co"># [53] highr_0.10         xfun_0.41          tibble_3.2.1       tidyselect_1.2.0  </span></span>
<span><span class="co"># [57] rstudioapi_0.15.0  knitr_1.45         farver_2.1.1       htmltools_0.5.7   </span></span>
<span><span class="co"># [61] labeling_0.4.3     rmarkdown_2.25     compiler_4.3.2     horseshoe_0.2.0</span></span></code></pre></div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-BrownBaseball" class="csl-entry">
Brown, Lawrence D. 2008. <span>“In-Season Prediction of Batting
Averages: A Field Test of Empirical <span>B</span>ayes and
<span>B</span>ayes Methodologies.”</span> <em>Annals of Applied
Statistics</em> 2 (1): 113–52.
</div>
<div id="ref-fgguts" class="csl-entry">
FanGraphs. 2023. <span>“Guts!”</span> <a href="https://www.fangraphs.com/guts.aspx" class="external-link">https://www.fangraphs.com/guts.aspx</a>.
</div>
<div id="ref-GuKoenkerBaseball" class="csl-entry">
Gu, Jiaying, and Roger Koenker. 2017. <span>“Empirical
<span>B</span>ayesball Remixed: Empirical <span>B</span>ayes Methods for
Longitudinal Data.”</span> <em>Journal of Applied Econometrics</em> 32
(3): 575–99.
</div>
<div id="ref-JiangZhangBaseball" class="csl-entry">
Jiang, Wenhua, and Cun-Hui Zhang. 2010. <span>“Empirical
<span>B</span>ayes <span>I</span>n-Season Prediction of Baseball Batting
Averages.”</span> In <em>Borrowing Strength: Theory Powering
Applications—a <span>F</span>estschrift for <span>L</span>awrence
<span>D</span>. <span>B</span>rown</em>, 6:263–73. Institute of
Mathematical Statistics Collections. Beachwood, OH: Institute of
Mathematical Statistics.
</div>
<div id="ref-drcplus" class="csl-entry">
Judge, Jonathan. 2019. <span>“Entirely Beyond WOWY: A Breakdown of
DRC+.”</span> <em>Baseball Prospectus</em>. <a href="https://www.baseballprospectus.com/news/article/48293/entirely-beyond-wowy-a-breakdown-of-drc/" class="external-link">https://www.baseballprospectus.com/news/article/48293/entirely-beyond-wowy-a-breakdown-of-drc/</a>.
</div>
<div id="ref-MixSQP" class="csl-entry">
Kim, Youngseok, Peter Carbonetto, Matthew Stephens, and Mihai Anitescu.
2020. <span>“A Fast Algorithm for Maximum Likelihood Estimation of
Mixture Proportions Using Sequential Quadratic Programming.”</span>
<em>Journal of Computational and Graphical Statistics</em> 29 (2):
261–73.
</div>
<div id="ref-NarasimhanEfron" class="csl-entry">
Narasimhan, Balasubramanian, and Bradley Efron. 2020.
<span>“deconvolveR: A g-Modeling Program for Deconvolution and Empirical
<span>Bayes</span> Estimation.”</span> <em>Journal of Statistical
Software</em> 94 (11): 1–20.
</div>
<div id="ref-robinson" class="csl-entry">
Robinson, David. 2017. <span>“Introduction to Empirical
<span>Bayes</span>: Examples from Baseball Statistics.”</span> <a href="https://github.com/dgrtwo/empirical-bayes-book" class="external-link">https://github.com/dgrtwo/empirical-bayes-book</a>.
</div>
<div id="ref-xwoba" class="csl-entry">
Sharpe, Sam. 2019. <span>“An Introduction to Expected Weighted
<span>O</span>n-Base Average (xwOBA).”</span> <em>MLB Technology
Blog</em>. <a href="https://technology.mlblogs.com/an-introduction-to-expected-weighted-on-base-average-xwoba-29d6070ba52b" class="external-link">https://technology.mlblogs.com/an-introduction-to-expected-weighted-on-base-average-xwoba-29d6070ba52b</a>.
</div>
<div id="ref-Tango" class="csl-entry">
Tango, T. M., M. G. Lichtman, and A. E. Dolphin. 2006. <em>The Book:
Playing the Percentages in Baseball</em>. TMA Press.
</div>
<div id="ref-ggplot2" class="csl-entry">
Wickham, Hadley. 2016. <em><span class="nocase">ggplot2</span>: Elegant
Graphics for Data Analysis</em>. New York, NY: Springer-Verlag.
</div>
<div id="ref-WillwerscheidDiss" class="csl-entry">
Willwerscheid, Jason. 2021. <span>“Empirical <span>Bayes</span> Matrix
Factorization: Methods and Applications.”</span> PhD thesis, Chicago,
IL: University of Chicago.
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Jason Willwerscheid, Matthew Stephens, Peter Carbonetto.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
