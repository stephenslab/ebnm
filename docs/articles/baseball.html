<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>An analysis of weighted on-base averages using the ebnm package • ebnm</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="An analysis of weighted on-base averages using the ebnm package">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">


    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">ebnm</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">1.1-38</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/stephenslab/ebnm" class="external-link">Source</a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>An analysis of weighted on-base averages using
the ebnm package</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/stephenslab/ebnm/blob/HEAD/vignettes/baseball.Rmd" class="external-link"><code>vignettes/baseball.Rmd</code></a></small>
      <div class="hidden name"><code>baseball.Rmd</code></div>

    </div>

    
    
<p>In this vignette, we illustrate the key features of
<strong>ebnm</strong> in an analysis of baseball statistics.</p>
<div class="section level2">
<h2 id="the-woba-data-set">The “wOBA” data set<a class="anchor" aria-label="anchor" href="#the-woba-data-set"></a>
</h2>
<p>We begin by loading and inspecting the <code>wOBA</code> data set,
which consists of wOBAs (“weighted on-base averages”) and standard
errors for the 2022 MLB regular season:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/stephenslab/ebnm" class="external-link">"ebnm"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"wOBA"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">)</span></span>
<span><span class="co"># [1] 688</span></span>
<span><span class="co">#   FanGraphsID           Name Team  PA     x     s</span></span>
<span><span class="co"># 1       19952     Khalil Lee  NYM   2 1.036 0.733</span></span>
<span><span class="co"># 2       16953 Chadwick Tromp  ATL   4 0.852 0.258</span></span>
<span><span class="co"># 3       19608     Otto Lopez  TOR  10 0.599 0.162</span></span>
<span><span class="co"># 4       24770   James Outman  LAD  16 0.584 0.151</span></span>
<span><span class="co"># 5        8090 Matt Carpenter  NYY 154 0.472 0.054</span></span>
<span><span class="co"># 6       15640    Aaron Judge  NYY 696 0.458 0.024</span></span></code></pre></div>
<p>Column “x” contains the observed wOBAs, which we interpret as
estimates of a player’s <em>hitting ability</em>. Column “s” gives
standard errors. (See below for background on the wOBA statistic and
details on how standard errors were calculated.)</p>
<p>The overall distribution of wOBAs appears as follows:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://ggplot2.tidyverse.org" class="external-link">"ggplot2"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">wOBA</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html" class="external-link">geom_histogram</a></span><span class="op">(</span>bins <span class="op">=</span> <span class="fl">64</span>, color <span class="op">=</span> <span class="st">"white"</span>,fill <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_classic</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="baseball_files/figure-html/woba-histogram-1.png" width="480" style="display: block; margin: auto;"></p>
<p>As the histogram shows, most players finished the season with a wOBA
between .200 and .400. A few had very high wOBAs (&gt;.500), while
others had wOBAs at or near zero. A casual inspection of the data
suggests that players with these extreme wOBAs were simply lucky (or
unlucky). For example, the 4 players with the highest wOBAs each had
fewer than 20 plate appearances. (The number of plate appearances, or
PAs, is the sample size over which wOBA is measured for each hitter, so
smaller numbers of PAs are generally associated with larger standard
errors.) It is unlikely that these players would have sustained their
high level of production over a full season’s worth of PAs!</p>
<p>In contrast, Aaron Judge’s production — which included a
record-breaking number of home runs — appears to be “real,” since it was
sustained over nearly 700 PAs. Other cases are more ambiguous: how, for
example, are we to assess Matt Carpenter, who had several exceptional
seasons between 2013 and 2018 but whose output steeply declined in
2019–2021 before his surprising “comeback” in 2022? An empirical Bayes
analysis can help to answer this and other questions.</p>
</div>
<div class="section level2">
<h2 id="the-ebnm-function">The “ebnm” function<a class="anchor" aria-label="anchor" href="#the-ebnm-function"></a>
</h2>
<p>Function <code><a href="../reference/ebnm.html">ebnm()</a></code> is the main interface for fitting the
empirical Bayes normal means model; it is a “Swiss army knife” that
allows for various choices of prior family
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝒢</mi><annotation encoding="application/x-tex">\mathcal{G}</annotation></semantics></math>
as well as providing multiple options for fitting and tuning models. For
example, we can fit a normal means model with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝒢</mi><annotation encoding="application/x-tex">\mathcal{G}</annotation></semantics></math>
taken to be the family of normal distributions as follows:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">wOBA</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">s</span> <span class="op">&lt;-</span> <span class="va">wOBA</span><span class="op">$</span><span class="va">s</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">wOBA</span><span class="op">$</span><span class="va">Name</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">s</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">wOBA</span><span class="op">$</span><span class="va">Name</span></span>
<span><span class="va">fit_normal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm.html">ebnm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, prior_family <span class="op">=</span> <span class="st">"normal"</span>, mode <span class="op">=</span> <span class="st">"estimate"</span><span class="op">)</span></span></code></pre></div>
<p>(The default behavior is to fix the prior mode at zero. Since we
certainly do not expect the distribution of true hitting ability to have
a mode at zero, we set <code>mode = "estimate"</code>.)</p>
<p>The <code>ebnm</code> package has a second model-fitting interface in
which each prior family gets its own function:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_normal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_normal.html">ebnm_normal</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, mode <span class="op">=</span> <span class="st">"estimate"</span><span class="op">)</span></span></code></pre></div>
<p>Textual and graphical overviews of results can be obtained using the
<code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> and <code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> methods. The
<code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> method appears as follows:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># Call:</span></span>
<span><span class="co"># ebnm_normal(x = x, s = s, mode = "estimate")</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># EBNM model was fitted to 688 observations with _heteroskedastic_ standard errors.</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># The fitted prior belongs to the _normal_ prior family.</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># 2 degrees of freedom were used to estimate the model.</span></span>
<span><span class="co"># The log likelihood for the model is 989.64.</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># Available posterior summaries: _mean_, _sd_.</span></span>
<span><span class="co"># Use method fitted() to access available summaries.</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># A posterior sampler is _not_ available.</span></span>
<span><span class="co"># One can be added via function ebnm_add_sampler().</span></span></code></pre></div>
<p>The <code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> method visualizes results, comparing the
“observed” values
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
(the initial wOBA estimates) against the empirical Bayes posterior mean
estimates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>i</mi></msub><annotation encoding="application/x-tex">\hat{\theta}_i</annotation></semantics></math>:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span></span></code></pre></div>
<p><img src="baseball_files/figure-html/plot-ebnm-normal-1.png" width="372" style="display: block; margin: auto;"></p>
<p>The dashed line shows the diagonal
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">x = y</annotation></semantics></math>,
which makes shrinkage effects clearly visible. In particular, the most
extreme wOBAs on either end of the spectrum are strongly shrunk towards
the league average (around .300).</p>
<p>Since the <code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> method returns a “ggplot” object <span class="citation">(Wickham 2016)</span>, the plot can be conveniently
customized using <code>ggplot2</code>. For example, we can vary the
color of points by the number of plate appearances:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">$</span><span class="va">PA</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"wOBA"</span>, y <span class="op">=</span> <span class="st">"EB estimate of true wOBA skill"</span>, </span>
<span>       color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">PA</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_gradient.html" class="external-link">scale_color_gradient</a></span><span class="op">(</span>low <span class="op">=</span> <span class="st">"blue"</span>, high <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code></pre></div>
<p><img src="baseball_files/figure-html/plot-ebnm-normal-better-1.png" width="444" style="display: block; margin: auto;"></p>
<p>The plot tells us that wOBAs associated with fewer plate appearances
(blue points) were shrunk toward the league average much more strongly
than wOBAs for hitters with many plate appearances (red points).</p>
<p>Let us revisit the first 6 hitters in the data set to see what the
EBNM model suggests about their true hitting ability. The method returns
a posterior summary for each hitter (by default, the posterior mean and
standard deviation):</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#                 mean     sd</span></span>
<span><span class="co"># Khalil Lee     0.303 0.0287</span></span>
<span><span class="co"># Chadwick Tromp 0.308 0.0286</span></span>
<span><span class="co"># Otto Lopez     0.310 0.0283</span></span>
<span><span class="co"># James Outman   0.311 0.0282</span></span>
<span><span class="co"># Matt Carpenter 0.339 0.0254</span></span>
<span><span class="co"># Aaron Judge    0.394 0.0184</span></span></code></pre></div>
<p>Estimates for the first four ballplayers are shrunk strongly toward
the league average, reflecting the fact that these players had very few
plate appearances. Carpenter had many more plate appearances (154) than
these other four players, but according to this model we should remain
skeptical about his strong performance; after factoring in the prior, we
judge his “true”’’” talent to be much closer to the league average,
downgrading an observed wOBA of .472 to the posterior mean estimate of
.339.</p>
</div>
<div class="section level2">
<h2 id="comparing-different-priors">Comparing different priors<a class="anchor" aria-label="anchor" href="#comparing-different-priors"></a>
</h2>
<p>Judge’s “true” talent is also estimated to be much lower (.394) than
his observed wOBA (.458) despite sustaining this high level of
production over a full season (696 PAs). For this reason, one might ask
whether a prior that is more flexible than the normal prior — that is, a
prior that can better adapt to “outliers” like Judge — might produce a
different result. The <strong>ebnm</strong> package is very well suited
to answering this question. For example, to obtain results using the
family of all unimodal priors rather than a normal prior, we need only
update the argument to <code>prior_family</code>:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_unimodal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm.html">ebnm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, prior_family <span class="op">=</span> <span class="st">"unimodal"</span>, mode <span class="op">=</span> <span class="st">"estimate"</span><span class="op">)</span></span></code></pre></div>
<p>It is straightforward to produce a side-by-side visualization of the
fitted models simply by including both models as arguments to the
<code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> method. We also use the <code>subset</code> argument
to focus on the results for Judge and other players with the most plate
appearances:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">top50</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/order.html" class="external-link">order</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">$</span><span class="va">PA</span>, decreasing <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">top50</span> <span class="op">&lt;-</span> <span class="va">top50</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">50</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span>, <span class="va">fit_unimodal</span>, subset <span class="op">=</span> <span class="va">top50</span><span class="op">)</span></span></code></pre></div>
<p><img src="baseball_files/figure-html/ebnm-normal-vs-unimodal-1.png" width="540" style="display: block; margin: auto;"></p>
<p>This plot illustrates the ability of the unimodal prior to better
adapt to the data: estimates for players with many plate appearances and
outlying performances (very high or very low wOBAs) are not adjusted
quite so strongly toward the league average. Judge’s estimated “true”
talent, for example, remains much closer to his observed wOBA:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"PA"</span>,<span class="st">"x"</span><span class="op">)</span><span class="op">]</span>,</span>
<span>             <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span>,</span>
<span>             <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit_unimodal</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"PA"</span>, <span class="st">"x"</span>, <span class="st">"mean_n"</span>, <span class="st">"sd_n"</span>, <span class="st">"mean_u"</span>, <span class="st">"sd_u"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#                 PA     x mean_n   sd_n mean_u   sd_u</span></span>
<span><span class="co"># Khalil Lee       2 1.036  0.303 0.0287  0.302 0.0277</span></span>
<span><span class="co"># Chadwick Tromp   4 0.852  0.308 0.0286  0.307 0.0306</span></span>
<span><span class="co"># Otto Lopez      10 0.599  0.310 0.0283  0.310 0.0315</span></span>
<span><span class="co"># James Outman    16 0.584  0.311 0.0282  0.311 0.0318</span></span>
<span><span class="co"># Matt Carpenter 154 0.472  0.339 0.0254  0.355 0.0430</span></span>
<span><span class="co"># Aaron Judge    696 0.458  0.394 0.0184  0.439 0.0155</span></span></code></pre></div>
<p>Carpenter’s estimated “true” talent is also higher, but is still
adjusted much more than Judge’s in light of Carpenter’s smaller sample
size. Interestingly, the unimodal prior also assigns greater uncertainty
(the ``sd_u’’ column) to Carpenter’s estimate than does the normal
prior.</p>
<p>Recall that the two normal means models differ only in the priors
used, so we can understand the differences in the shrinkage behavior of
these models by inspecting the priors. Calling <code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> with
<code>incl_cdf = TRUE</code> shows the cumulative distribution functions
(CDFs) of the fitted priors
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>g</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\hat{g}</annotation></semantics></math>.
Since we are particularly interested in understanding the differences in
shrinkage behavior for large wOBAs such as Judge’s, we create a second
plot that zooms in on the interval between .350 and .450:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://wilkelab.org/cowplot/" class="external-link">"cowplot"</a></span><span class="op">)</span></span>
<span><span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span>, <span class="va">fit_unimodal</span>, incl_cdf <span class="op">=</span> <span class="cn">TRUE</span>, incl_pm <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html" class="external-link">xlim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">.250</span>, <span class="fl">.350</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/guides.html" class="external-link">guides</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span></span>
<span><span class="va">p2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span>, <span class="va">fit_unimodal</span>, incl_cdf <span class="op">=</span> <span class="cn">TRUE</span>, incl_pm <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html" class="external-link">lims</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">.350</span>, <span class="fl">.450</span><span class="op">)</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.95</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://wilkelab.org/cowplot/reference/plot_grid.html" class="external-link">plot_grid</a></span><span class="op">(</span><span class="va">p1</span>, <span class="va">p2</span>, nrow <span class="op">=</span> <span class="fl">1</span>, ncol <span class="op">=</span> <span class="fl">2</span>, rel_widths <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="baseball_files/figure-html/ebnm-normal-vs-unimodal-3-1.png" width="780" style="display: block; margin: auto;"></p>
<p>The plot on the right shows that the fitted normal prior has almost
no mass above .400, explaining why Judge’s estimate is shrunk so
strongly toward the league average, whereas the unimodal prior is
flexible enough to permit posterior estimates above .400.</p>
<p>The posterior means and standard errors returned from the
<code><a href="../reference/ebnm.html">ebnm()</a></code> call cannot be used to obtain credible intervals
(except for the special case of the normal prior). Therefore, we provide
additional methods <code><a href="https://rdrr.io/r/stats/quantile.html" class="external-link">quantile()</a></code> and <code><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint()</a></code>,
which return, respectively, posterior quantiles and posterior credible
intervals, defined as the narrowest <em>continuous</em> intervals
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>a</mi><mi>i</mi></msub><mo>,</mo><msub><mi>b</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">[a_i, b_i]</annotation></semantics></math>
such that the “true mean”
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>θ</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\theta_i</annotation></semantics></math>
is in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>a</mi><mi>i</mi></msub><mo>,</mo><msub><mi>b</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">[a_i, b_i]</annotation></semantics></math>
with posterior probability at least
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mi>α</mi></mrow><annotation encoding="application/x-tex">1 - \alpha</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>∈</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\alpha \in (0, 1)</annotation></semantics></math>.
Both methods are implemented using Monte Carlo techniques, which can be
slow for large data sets, so credible intervals are not computed by
default.<br>
We add a Monte Carlo sampler using function
<code><a href="../reference/ebnm_add_sampler.html">ebnm_add_sampler()</a></code>; alternatively, we could have added a
sampler in our initial calls to <code><a href="../reference/ebnm.html">ebnm()</a></code> by specifying
<code>output = output_all()</code>. We then compute, 80% credible
intervals for the EBNM model with unimodal prior, setting a seed for
reproducibility:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_unimodal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_add_sampler.html">ebnm_add_sampler</a></span><span class="op">(</span><span class="va">fit_unimodal</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit_unimodal</span>, level <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#                CI.lower CI.upper</span></span>
<span><span class="co"># Khalil Lee        0.277    0.328</span></span>
<span><span class="co"># Chadwick Tromp    0.277    0.334</span></span>
<span><span class="co"># Otto Lopez        0.277    0.336</span></span>
<span><span class="co"># James Outman      0.277    0.335</span></span>
<span><span class="co"># Matt Carpenter    0.277    0.389</span></span>
<span><span class="co"># Aaron Judge       0.428    0.458</span></span></code></pre></div>
<p>Interestingly, the 80% credible interval for Carpenter is very wide,
and shares the same lower bound as the first four ballplayers (who,
recall, have very few plate appearances).</p>
</div>
<div class="section level2">
<h2 id="reanalyzing-the-data-using-a-nonparametric-prior">Reanalyzing the data using a nonparametric prior<a class="anchor" aria-label="anchor" href="#reanalyzing-the-data-using-a-nonparametric-prior"></a>
</h2>
<p>Above, we demonstrated how the <code>ebnm</code> package makes it is
easy to perform EBNM analyses with different types of priors, then
compared results across two different choices of prior family. Each of
these families makes different assumptions about the data which, <em>a
priori</em>, may be more or less plausible. An alternative to prior
families that make specific assumptions about the data is to use the
prior family that contains <em>all</em> distributions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>𝒢</mi><mrow><mi mathvariant="normal">n</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">e</mi></mrow></msub><annotation encoding="application/x-tex">\mathcal{G}_{\mathrm{npmle}}</annotation></semantics></math>,
which is in a sense “assumption free.” Note that although nonparametric
priors require specialized computational techniques, switching to a
nonparametric prior is seamless in <strong>ebnm</strong>, as these
implementation details are hidden. Similar to above, we need only make a
single change to the <code>prior_family</code> argument:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_npmle</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm.html">ebnm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, prior_family <span class="op">=</span> <span class="st">"npmle"</span><span class="op">)</span></span></code></pre></div>
<p>(Note that because the family
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>𝒢</mi><mrow><mi mathvariant="normal">n</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">e</mi></mrow></msub><annotation encoding="application/x-tex">\mathcal{G}_{\mathrm{npmle}}</annotation></semantics></math>
is not unimodal, the <code>mode = "estimate"</code> option is not
relevant here.)</p>
<p>Although the implementation details are hidden by default, it can
sometimes be helpful to see what is going on “behind the scenes,”
particularly for flagging or diagnosing issues. By default, ebnm uses
the mixsqp package <span class="citation">(Kim et al. 2020)</span> to
fit the NPMLE
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>g</mi><mo accent="true">̂</mo></mover><mo>∈</mo><msub><mi>𝒢</mi><mrow><mi mathvariant="normal">n</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\hat{g} \in
\mathcal{G}_{\mathrm{npmle}}</annotation></semantics></math>. We can
monitor convergence of the mix-SQP optimization algorithm by setting the
<code>verbose</code> control argument to <code>TRUE</code>:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_npmle</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm.html">ebnm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, prior_family <span class="op">=</span> <span class="st">"npmle"</span>, </span>
<span>                  control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Running mix-SQP algorithm 0.3-54 on 688 x 95 matrix</span></span>
<span><span class="co"># convergence tol. (SQP):     1.0e-08</span></span>
<span><span class="co"># conv. tol. (active-set):    1.0e-10</span></span>
<span><span class="co"># zero threshold (solution):  1.0e-08</span></span>
<span><span class="co"># zero thresh. (search dir.): 1.0e-14</span></span>
<span><span class="co"># l.s. sufficient decrease:   1.0e-02</span></span>
<span><span class="co"># step size reduction factor: 7.5e-01</span></span>
<span><span class="co"># minimum step size:          1.0e-08</span></span>
<span><span class="co"># max. iter (SQP):            1000</span></span>
<span><span class="co"># max. iter (active-set):     20</span></span>
<span><span class="co"># number of EM iterations:    10</span></span>
<span><span class="co"># Computing SVD of 688 x 95 matrix.</span></span>
<span><span class="co"># Matrix is not low-rank; falling back to full matrix.</span></span>
<span><span class="co"># iter        objective max(rdual) nnz stepsize max.diff nqp nls</span></span>
<span><span class="co">#    1 +9.583407733e-01  -- EM --   95 1.00e+00 6.08e-02  --  --</span></span>
<span><span class="co">#    2 +8.298700300e-01  -- EM --   95 1.00e+00 2.87e-02  --  --</span></span>
<span><span class="co">#    3 +7.955308369e-01  -- EM --   95 1.00e+00 1.60e-02  --  --</span></span>
<span><span class="co">#    4 +7.819858634e-01  -- EM --   68 1.00e+00 1.05e-02  --  --</span></span>
<span><span class="co">#    5 +7.753787534e-01  -- EM --   53 1.00e+00 7.57e-03  --  --</span></span>
<span><span class="co">#    6 +7.717040208e-01  -- EM --   49 1.00e+00 5.73e-03  --  --</span></span>
<span><span class="co">#    7 +7.694760705e-01  -- EM --   47 1.00e+00 4.48e-03  --  --</span></span>
<span><span class="co">#    8 +7.680398878e-01  -- EM --   47 1.00e+00 3.58e-03  --  --</span></span>
<span><span class="co">#    9 +7.670690681e-01  -- EM --   44 1.00e+00 2.91e-03  --  --</span></span>
<span><span class="co">#   10 +7.663865515e-01  -- EM --   42 1.00e+00 2.40e-03  --  --</span></span>
<span><span class="co">#    1 +7.658902386e-01 +6.493e-02  39  ------   ------   --  --</span></span>
<span><span class="co">#    2 +7.655114904e-01 +5.285e-02  19 1.00e+00 9.88e-02  20   1</span></span>
<span><span class="co">#    3 +7.627839841e-01 +1.411e-02   7 1.00e+00 1.28e-01  20   1</span></span>
<span><span class="co">#    4 +7.626270875e-01 +2.494e-04   7 1.00e+00 3.23e-01  12   1</span></span>
<span><span class="co">#    5 +7.626270755e-01 +1.748e-08   7 1.00e+00 4.94e-04   2   1</span></span>
<span><span class="co">#    6 +7.626270755e-01 -2.796e-08   7 1.00e+00 2.76e-07   2   1</span></span>
<span><span class="co"># Optimization took 0.03 seconds.</span></span>
<span><span class="co"># Convergence criteria met---optimal solution found.</span></span></code></pre></div>
<p>This output shows no issues with convergence of the optimization
algorithm; the mix-SQP algorithm converged to the solution (up to
numerical rounding error) in only 6 iterations (not counting the 10
initial EM iterations). In some cases, convergence issues can arise when
fitting nonparametric models to large or complex data sets, and
revealing the details of the optimization can help to pinpoint these
issues.</p>
<p>Let us visually compare the three fits obtained so far:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span>, <span class="va">fit_unimodal</span>, <span class="va">fit_npmle</span>, incl_cdf <span class="op">=</span> <span class="cn">TRUE</span>, subset <span class="op">=</span> <span class="va">top50</span><span class="op">)</span></span></code></pre></div>
<p><img src="baseball_files/figure-html/plot-npmle-1.png" width="510" style="display: block; margin: auto;"><img src="baseball_files/figure-html/plot-npmle-2.png" width="510" style="display: block; margin: auto;"></p>
<p>As before, estimates largely agree, differing primarily at the tails.
Both the unimodal prior family and the NPMLE are sufficiently flexible
to avoid the strong shrinkage behavior of the normal prior family.</p>
<p>Fits can be compared quantitatively using the <code><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik()</a></code>
method, which, in addition to the log likelihood for each model,
usefully reports the number of free parameters (i.e., degrees of
freedom):</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">fit_unimodal</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">fit_npmle</span><span class="op">)</span></span>
<span><span class="co"># 'log Lik.' 992.6578 (df=40)</span></span>
<span><span class="co"># 'log Lik.' 994.193 (df=94)</span></span></code></pre></div>
<p>A nonparametric prior
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝒢</mi><annotation encoding="application/x-tex">\mathcal{G}</annotation></semantics></math>
is approximated by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
mixture components on a fixed grid, with mixture proportions to be
estimated. We can infer from the above output that the family of
unimodal priors has been approximated by a family of mixtures over
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>=</mo><mn>41</mn></mrow><annotation encoding="application/x-tex">K = 41</annotation></semantics></math>
fixed components, while
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>𝒢</mi><mtext mathvariant="normal">npmle</mtext></msub><annotation encoding="application/x-tex">\mathcal{G}_\text{npmle}</annotation></semantics></math>
has been approximated as a family of mixtures over a grid of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>=</mo><mn>95</mn></mrow><annotation encoding="application/x-tex">K = 95</annotation></semantics></math>
point masses spanning the range of the data. (The number of degrees of
freedom is one fewer than
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
because the mixture proportions must always sum to 1, which removes one
degree of freedom from the estimation of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝛑</mi><annotation encoding="application/x-tex">{\boldsymbol{\pi}}</annotation></semantics></math>.)</p>
<p>The default behaviour for nonparametric prior families is to choose
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
such that the likelihood obtained using estimate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>g</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\hat{g}</annotation></semantics></math>
should be (on average) within one log-likelihood unit of the optimal
estimate from among the entire nonparametric family
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝒢</mi><annotation encoding="application/x-tex">\mathcal{G}</annotation></semantics></math><span class="citation">(see Willwerscheid 2021)</span>. Thus, a finer
approximating grid should not yield a large improvement in the
log-likelihood. We can check this by using
<code><a href="../reference/ebnm_scale_npmle.html">ebnm_scale_npmle()</a></code> to create a finer grid:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">scale_npmle</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_scale_npmle.html">ebnm_scale_npmle</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, KLdiv_target <span class="op">=</span> <span class="fl">0.001</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, </span>
<span>                                max_K <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">fit_npmle_finer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_npmle.html">ebnm_npmle</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, scale <span class="op">=</span> <span class="va">scale_npmle</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">fit_npmle</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">fit_npmle_finer</span><span class="op">)</span></span>
<span><span class="co"># 'log Lik.' 994.193 (df=94)</span></span>
<span><span class="co"># 'log Lik.' 994.2705 (df=528)</span></span></code></pre></div>
<p>As the theory predicts, a much finer grid, with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>=</mo><mn>529</mn></mrow><annotation encoding="application/x-tex">K = 529</annotation></semantics></math>,
results in only a modest improvement in the log-likelihood.
<strong>ebnm</strong> provides similar functions
<code><a href="../reference/ebnm_scale_unimix.html">ebnm_scale_unimix()</a></code> and <code><a href="../reference/ebnm_scale_normalmix.html">ebnm_scale_normalmix()</a></code>
to customize grids for, respectively, unimodal and normal scale mixture
prior families.</p>
<p>One potential issue with the NPMLE is that, since it is discrete (as
the above CDF plot makes apparent), observations are variously shrunk
toward one of the support points, which can result in poor interval
estimates. For illustration, we calculate 80% intervals using 10% and
90% quantiles (note that this is not the same as using the
<code><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint()</a></code> method with <code>level = 0.8</code>, since
<code><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint()</a></code> returns the <em>narrowest</em> continuous
intervals covering 80% of the posterior probability):</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_npmle</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_add_sampler.html">ebnm_add_sampler</a></span><span class="op">(</span><span class="va">fit_npmle</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/quantile.html" class="external-link">quantile</a></span><span class="op">(</span><span class="va">fit_npmle</span>, probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.9</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#                  10%   90%</span></span>
<span><span class="co"># Khalil Lee     0.276 0.342</span></span>
<span><span class="co"># Chadwick Tromp 0.276 0.342</span></span>
<span><span class="co"># Otto Lopez     0.276 0.342</span></span>
<span><span class="co"># James Outman   0.276 0.342</span></span>
<span><span class="co"># Matt Carpenter 0.309 0.430</span></span>
<span><span class="co"># Aaron Judge    0.419 0.430</span></span></code></pre></div>
<p>Each interval endpoint is constrained to lie at one of the support
points of the NPMLE
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>g</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\hat{g}</annotation></semantics></math>.
The interval estimate for Judge strikes us as far too narrow. Indeed,
the NPMLE can sometimes yield degenerate interval estimates:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit_npmle</span>, level <span class="op">=</span> <span class="fl">0.8</span>, parm <span class="op">=</span> <span class="st">"Aaron Judge"</span><span class="op">)</span></span>
<span><span class="co">#              CI.lower  CI.upper</span></span>
<span><span class="co"># Aaron Judge 0.4298298 0.4298298</span></span></code></pre></div>
<p>To address this and other issues, the <strong>deconvolveR</strong>
package <span class="citation">(Narasimhan and Efron 2020)</span> uses a
penalized likelihood that encourages “smooth” priors
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>g</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\hat{g}</annotation></semantics></math>;
that is, priors
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>g</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\hat{g}</annotation></semantics></math>
for which few of the mixture proportions are zero:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_deconv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_deconvolver.html">ebnm_deconvolver</a></span><span class="op">(</span><span class="va">x</span> <span class="op">/</span> <span class="va">s</span>, output <span class="op">=</span> <span class="fu"><a href="../reference/ebnm.html">ebnm_output_all</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_deconv</span>, incl_cdf <span class="op">=</span> <span class="cn">TRUE</span>, incl_pm <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p><img src="baseball_files/figure-html/ebnm-deconvolver-1.png" width="300" style="display: block; margin: auto;"></p>
<p>Note however that since package <strong>deconvolveR</strong> fits a
model to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>-scores
rather than observations and associated standard errors, the “true”
means
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>θ</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
being estimated are
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>-scores
rather than raw wOBA skill. While this may be<br>
reasonable in many settings, it does not seem appropriate for the wOBA
data:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit_deconv</span>, level <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">*</span> <span class="va">s</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#                CI.lower CI.upper</span></span>
<span><span class="co"># Khalil Lee        0.000    1.600</span></span>
<span><span class="co"># Chadwick Tromp    0.563    1.127</span></span>
<span><span class="co"># Otto Lopez        0.442    0.796</span></span>
<span><span class="co"># James Outman      0.412    0.742</span></span>
<span><span class="co"># Matt Carpenter    0.413    0.531</span></span>
<span><span class="co"># Aaron Judge       0.406    0.459</span></span></code></pre></div>
<p>These interval estimates do not match our basic intuitions; for
example, a wOBA over .600 has never been sustained over a full
season.</p>
</div>
<div class="section level2">
<h2 id="background-on-the-weighted-on-base-average">Background on the “weighted on-base average”<a class="anchor" aria-label="anchor" href="#background-on-the-weighted-on-base-average"></a>
</h2>
<p>A longstanding tradition in empirical Bayes research is to include an
analysis of batting averages using data from Major League Baseball; see,
for example, <span class="citation">Brown (2008)</span>; <span class="citation">Jiang and Zhang (2010)</span>; <span class="citation">Gu and Koenker (2017)</span>. Until recently, batting
averages were the most important measurement of a hitter’s performance,
with the prestigious yearly “batting title” going to the hitter with the
highest average. However, with the rise of baseball analytics, metrics
that better correlate to teams’ overall run production have become
increasingly preferred. One such metric is wOBA (“weighted on-base
average”), which is both an excellent measure of a hitter’s offensive
production and, unlike competing metrics such as MLB’s xwOBA <span class="citation">(Sharpe 2019)</span> or Baseball Prospectus’s DRC+
<span class="citation">(Judge 2019)</span>, can be calculated using
publicly available data and methods.</p>
<p>Initially proposed by <span class="citation">Tango, Lichtman, and
Dolphin (2006)</span>, wOBA assigns values (“weights”) to hitting
outcomes according to how much the outcome contributes on average to run
production. For example, while batting average treats singles
identically to home runs, wOBA gives a hitter more than twice as much
credit for a home run. (Note that weights are updated from year to year,
but wOBA weights for singles have remained near 0.9 for the last several
decades, while weights for home runs have hovered around 2.0; see <span class="citation">FanGraphs (2023)</span>.)</p>
<p>Given a vector of wOBA weights
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝐰</mi><annotation encoding="application/x-tex">\mathbf{w}</annotation></semantics></math>,
hitter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>’s
wOBA is the weighted average
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><msup><mi>𝐰</mi><mi>⊤</mi></msup><msup><mi>𝐳</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mi>/</mi><msub><mi>n</mi><mi>i</mi></msub><mo>,</mo></mrow><annotation encoding="application/x-tex">
x_i = \mathbf{w}^\top \mathbf{z}^{(i)} / n_i,
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝐳</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>z</mi><mn>1</mn><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>,</mo><mi>…</mi><mo>,</mo><msubsup><mi>z</mi><mn>7</mn><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{z}^{(i)} = (z_1^{(i)}, \ldots, z_7^{(i)})</annotation></semantics></math>
tallies outcomes (singles, doubles, triples, home runs, walks,
hit-by-pitches and outs) over the hitter’s
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><mi>i</mi></msub><annotation encoding="application/x-tex">n_i</annotation></semantics></math>
plate appearances (PAs). Modeling hitting outcomes as i.i.d.
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝐳</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>∼</mo><mtext mathvariant="normal">Multinomial</mtext><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>n</mi><mi>i</mi></msub><mo>,</mo><msup><mi>𝛑</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">
\mathbf{z}^{(i)} \sim \text{Multinomial}(n_i, \mathbf{\pi}^{(i)}),
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝛑</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>π</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msubsup><mi>π</mi><mn>7</mn><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{\pi}^{(i)} = (\pi_1, \ldots, \pi_7^{(i)})</annotation></semantics></math>
is the vector of “true” outcome probabilities for hitter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>,
we can regard
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
as a point estimate for the hitter’s “true wOBA skill”,
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub><mo>=</mo><msup><mi>𝐰</mi><mi>⊤</mi></msup><msup><mi>𝛑</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mi>.</mi></mrow><annotation encoding="application/x-tex">
\theta_i = \mathbf{w}^\top \mathbf{\pi}^{(i)}.
</annotation></semantics></math> Standard errors for the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>’s
can be estimated as
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>s</mi><mi>i</mi><mn>2</mn></msubsup><mo>=</mo><msup><mi>𝐰</mi><mi>⊤</mi></msup><msup><mover><mi>𝚺</mi><mo accent="true">̂</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mi>𝐰</mi><mi>/</mi><msub><mi>n</mi><mi>i</mi></msub><mo>,</mo></mrow><annotation encoding="application/x-tex">
s_i^2 = \mathbf{w}^\top \hat{\mathbf{\Sigma}}^{(i)} \mathbf{w}/n_i,
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mover><mi>𝚺</mi><mo accent="true">̂</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\hat{\mathbf{\Sigma}}^{(i)}</annotation></semantics></math>
is the estimate of the covariance matrix for the multinomial model
obtained by setting
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝛑</mi><mo>=</mo><mover><mi>𝛑</mi><mo accent="true">̂</mo></mover></mrow><annotation encoding="application/x-tex">\mathbf{\pi} =
\hat{\mathbf{\pi}}</annotation></semantics></math>, where
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>𝛑</mi><mo accent="true">̂</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><msup><mi>𝐳</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mi>/</mi><msub><mi>n</mi><mi>i</mi></msub><mi>.</mi></mrow><annotation encoding="application/x-tex">
\hat{\mathbf{\pi}}^{(i)} = \mathbf{z}^{(i)}/n_i.
</annotation></semantics></math> (To deal with small sample sizes, we
conservatively lower bound each standard error by the standard error
that would be obtained by plugging in league-average event probabilities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>𝛑</mi><mo accent="true">̂</mo></mover><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">g</mi></mrow></msub><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msup><mi>𝐳</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mi>/</mi><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msub><mi>n</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\hat{\mathbf{\pi}}_{\mathrm{lg}} = \sum_{i=1}^N \mathbf{z}^{(i)}/
\sum_{i=1}^N n_i</annotation></semantics></math>, where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
is the number of hitters in the data set.)</p>
<p>The relative complexity of wOBA makes it well suited for analysis via
<strong>ebnm</strong>. With batting average, a common approach is to
obtain empirical Bayes estimates using a beta-binomial model (see, for
example, <span class="citation">Robinson (2017)</span>). With wOBA, one
can estimate hitting outcome probabilities by way of a
Dirichlet-multinomial model; alternatively, one can approximate the
likelihood as normal and fit an EBNM model directly to the observed
wOBAs. We take the latter approach.</p>
</div>
<div class="section level2">
<h2 id="session-information">Session information<a class="anchor" aria-label="anchor" href="#session-information"></a>
</h2>
<p>The following R version and packages were used to generate this
vignette:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html" class="external-link">sessionInfo</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co"># R version 4.5.1 (2025-06-13)</span></span>
<span><span class="co"># Platform: aarch64-apple-darwin20</span></span>
<span><span class="co"># Running under: macOS Sequoia 15.5</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># Matrix products: default</span></span>
<span><span class="co"># BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib </span></span>
<span><span class="co"># LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># locale:</span></span>
<span><span class="co"># [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># time zone: America/New_York</span></span>
<span><span class="co"># tzcode source: internal</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># attached base packages:</span></span>
<span><span class="co"># [1] stats     graphics  grDevices utils     datasets  methods   base     </span></span>
<span><span class="co"># </span></span>
<span><span class="co"># other attached packages:</span></span>
<span><span class="co"># [1] cowplot_1.2.0 ggplot2_3.5.2 ebnm_1.1-38  </span></span>
<span><span class="co"># </span></span>
<span><span class="co"># loaded via a namespace (and not attached):</span></span>
<span><span class="co">#  [1] sass_0.4.10        generics_0.1.4     ashr_2.2-63        lattice_0.22-7    </span></span>
<span><span class="co">#  [5] digest_0.6.37      magrittr_2.0.3     evaluate_1.0.4     grid_4.5.1        </span></span>
<span><span class="co">#  [9] RColorBrewer_1.1-3 fastmap_1.2.0      jsonlite_2.0.0     Matrix_1.7-3      </span></span>
<span><span class="co"># [13] mixsqp_0.3-54      scales_1.4.0       truncnorm_1.0-9    invgamma_1.2      </span></span>
<span><span class="co"># [17] textshaping_1.0.1  jquerylib_0.1.4    cli_3.6.5          rlang_1.1.6       </span></span>
<span><span class="co"># [21] deconvolveR_1.2-1  splines_4.5.1      withr_3.0.2        cachem_1.1.0      </span></span>
<span><span class="co"># [25] yaml_2.3.10        tools_4.5.1        SQUAREM_2021.1     dplyr_1.1.4       </span></span>
<span><span class="co"># [29] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4    fs_1.6.6          </span></span>
<span><span class="co"># [33] htmlwidgets_1.6.4  trust_0.1-8        ragg_1.4.0         irlba_2.3.5.1     </span></span>
<span><span class="co"># [37] pkgconfig_2.0.3    desc_1.4.3         pkgdown_2.1.3      pillar_1.11.0     </span></span>
<span><span class="co"># [41] bslib_0.9.0        gtable_0.3.6       glue_1.8.0         Rcpp_1.1.0        </span></span>
<span><span class="co"># [45] systemfonts_1.2.3  xfun_0.52          tibble_3.3.0       tidyselect_1.2.1  </span></span>
<span><span class="co"># [49] rstudioapi_0.17.1  knitr_1.50         farver_2.1.2       htmltools_0.5.8.1 </span></span>
<span><span class="co"># [53] rmarkdown_2.29     labeling_0.4.3     compiler_4.5.1     horseshoe_0.2.0</span></span></code></pre></div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-BrownBaseball" class="csl-entry">
Brown, Lawrence D. 2008. <span>“In-Season Prediction of Batting
Averages: A Field Test of Empirical <span>B</span>ayes and
<span>B</span>ayes Methodologies.”</span> <em>Annals of Applied
Statistics</em> 2 (1): 113–52.
</div>
<div id="ref-fgguts" class="csl-entry">
FanGraphs. 2023. <span>“Guts!”</span> <a href="https://www.fangraphs.com/guts.aspx" class="external-link">https://www.fangraphs.com/guts.aspx</a>.
</div>
<div id="ref-GuKoenkerBaseball" class="csl-entry">
Gu, Jiaying, and Roger Koenker. 2017. <span>“Empirical
<span>B</span>ayesball Remixed: Empirical <span>B</span>ayes Methods for
Longitudinal Data.”</span> <em>Journal of Applied Econometrics</em> 32
(3): 575–99.
</div>
<div id="ref-JiangZhangBaseball" class="csl-entry">
Jiang, Wenhua, and Cun-Hui Zhang. 2010. <span>“Empirical
<span>B</span>ayes <span>I</span>n-Season Prediction of Baseball Batting
Averages.”</span> In <em>Borrowing Strength: Theory Powering
Applications—a <span>F</span>estschrift for <span>L</span>awrence
<span>D</span>. <span>B</span>rown</em>, 6:263–73. Institute of
Mathematical Statistics Collections. Beachwood, OH: Institute of
Mathematical Statistics.
</div>
<div id="ref-drcplus" class="csl-entry">
Judge, Jonathan. 2019. <span>“Entirely Beyond WOWY: A Breakdown of
DRC+.”</span> <em>Baseball Prospectus</em>. <a href="https://www.baseballprospectus.com/news/article/48293/entirely-beyond-wowy-a-breakdown-of-drc/" class="external-link">https://www.baseballprospectus.com/news/article/48293/entirely-beyond-wowy-a-breakdown-of-drc/</a>.
</div>
<div id="ref-MixSQP" class="csl-entry">
Kim, Youngseok, Peter Carbonetto, Matthew Stephens, and Mihai Anitescu.
2020. <span>“A Fast Algorithm for Maximum Likelihood Estimation of
Mixture Proportions Using Sequential Quadratic Programming.”</span>
<em>Journal of Computational and Graphical Statistics</em> 29 (2):
261–73.
</div>
<div id="ref-NarasimhanEfron" class="csl-entry">
Narasimhan, Balasubramanian, and Bradley Efron. 2020.
<span>“deconvolveR: A g-Modeling Program for Deconvolution and Empirical
<span>Bayes</span> Estimation.”</span> <em>Journal of Statistical
Software</em> 94 (11): 1–20.
</div>
<div id="ref-robinson" class="csl-entry">
Robinson, David. 2017. <span>“Introduction to Empirical
<span>Bayes</span>: Examples from Baseball Statistics.”</span> <a href="https://github.com/dgrtwo/empirical-bayes-book" class="external-link">https://github.com/dgrtwo/empirical-bayes-book</a>.
</div>
<div id="ref-xwoba" class="csl-entry">
Sharpe, Sam. 2019. <span>“An Introduction to Expected Weighted
<span>O</span>n-Base Average (xwOBA).”</span> <em>MLB Technology
Blog</em>. <a href="https://technology.mlblogs.com/an-introduction-to-expected-weighted-on-base-average-xwoba-29d6070ba52b" class="external-link">https://technology.mlblogs.com/an-introduction-to-expected-weighted-on-base-average-xwoba-29d6070ba52b</a>.
</div>
<div id="ref-Tango" class="csl-entry">
Tango, T. M., M. G. Lichtman, and A. E. Dolphin. 2006. <em>The Book:
Playing the Percentages in Baseball</em>. TMA Press.
</div>
<div id="ref-ggplot2" class="csl-entry">
Wickham, Hadley. 2016. <em><span class="nocase">ggplot2</span>: Elegant
Graphics for Data Analysis</em>. New York, NY: Springer-Verlag.
</div>
<div id="ref-WillwerscheidDiss" class="csl-entry">
Willwerscheid, Jason. 2021. <span>“Empirical <span>Bayes</span> Matrix
Factorization: Methods and Applications.”</span> PhD thesis, Chicago,
IL: University of Chicago.
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Jason Willwerscheid, Matthew Stephens, Peter Carbonetto.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

      </footer>
</div>






  </body>
</html>
