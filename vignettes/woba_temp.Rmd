Given a vector of wOBA weights $\mathbf{w}$, hitter $i$'s wOBA is the
weighted average
\begin{equation}
x_i \colonequals \mathbf{w}^\top \mathbf{z}^{(i)} / n_i,
\end{equation}
where $\mathbf{z}^{(i)} = (z_1^{(i)}, \ldots, z_7^{(i)})$ tallies
  outcomes (singles, doubles, triples, home runs, walks,
  hit-by-pitches, and outs) over the hitter's $n_i$ plate appearances
  (PAs). Modeling hitting outcomes as i.i.d.
\begin{equation} 
\mathbf{z}^{(i)} \sim \text{Multinomial}(n_i, {\bm\pi}^{(i)}),
\label{eqn:woba_multinom}
\end{equation}
where ${\bm\pi}^{(i)} = (\pi_1, \ldots, \pi_7^{(i)})$ is the vector of
``true'' outcome probabilities for hitter $i$, we can regard $x_i$ as
a point estimate for the hitter's ``true wOBA skill''
\begin{equation} 
\theta_i \colonequals \mathbf{w}^\top {\bm\pi}^{(i)}.
\end{equation}
Standard errors for the $x_i$'s can be estimated as
\begin{equation}
s_i^2 = \mathbf{w}^\top \hat{\bm\Sigma}^{(i)} \mathbf{w}/n_i,
\end{equation}
where $\hat{\bm\Sigma}^{(i)}$ is the estimate of the covariance matrix
for the multinomial model \eqref{eqn:woba_multinom} obtained by
setting ${\bm\pi} = \hat{\bm\pi}$,\footnote{To deal with small
sample sizes, we conservatively lower bound each standard error by
the standard error that would be obtained by plugging in
league-average event probabilities $\hat{\bm\pi}_{\mathrm{lg}} =
\sum_{i=1}^N \mathbf{z}^{(i)}/ \sum_{i=1}^N n_i$, where $N$ is the
number of hitters in the data set.} where
\begin{equation} 
\hat{\bm\pi}^{(i)} = \mathbf{z}^{(i)}/n_i.
\end{equation}

The relative complexity of wOBA makes it well suited for analysis via
\pkg{ebnm}. With batting average, a common approach is to obtain
empirical Bayes estimates using a beta-binomial model (see, for example, \citealt{robinson}). With wOBA,
one can estimate hitting outcome probabilities by way of a
Dirichlet-multinomial model; alternatively, one can approximate the likelihood as normal and
fit an EBNM model directly to the observed wOBAs. In the following, we take the latter approach.

We begin by loading and inspecting the \code{wOBA} data set, which consists of wOBAs and
standard errors for the 2022 MLB regular season:
\begin{CodeChunk}
\begin{CodeInput}
R> library("ebnm")
R> data("wOBA")
R> nrow(wOBA)
\end{CodeInput}
\begin{CodeOutput}
[1] 688
\end{CodeOutput}
\begin{CodeInput}
R> head(wOBA)
\end{CodeInput}
\begin{CodeOutput}
  FanGraphsID           Name Team  PA     x     s
1       19952     Khalil Lee  NYM   2 1.036 0.733
2       16953 Chadwick Tromp  ATL   4 0.852 0.258
3       19608     Otto Lopez  TOR  10 0.599 0.162
4       24770   James Outman  LAD  16 0.584 0.151
5        8090 Matt Carpenter  NYY 154 0.472 0.054
6       15640    Aaron Judge  NYY 696 0.458 0.024
\end{CodeOutput}
\end{CodeChunk}

Column ``x''  contains each player's wOBA for the 2022 season,
which we regard as an estimate of the player's ``true'' wOBA
skill. Column ``s''  provides standard errors.

\begin{figure}[!t]
\centering
\includegraphics[width=0.75\textwidth]{figures/wOBA_dist.pdf}
\caption{Histogram of MLB player wOBAs from the 2022 season.}
\label{fig:wOBA_dist}
\end{figure}

Next, we visualize the overall distribution of wOBAs:
\begin{CodeChunk}
\begin{CodeInput}
R> library("ggplot2")
R> ggplot(wOBA, aes(x = x)) +
+    geom_histogram(bins = 64, color = "black") +
+    theme_classic()
\end{CodeInput}
\end{CodeChunk}

As the histogram (Figure~\ref{fig:wOBA_dist}) shows, most players finished the season with a wOBA
between .200 and .400.\footnote{Throughout, we follow the convention
  of reporting wOBAs using three decimal places.} A few had very high
wOBAs ($>$.500), while others had wOBAs at or near zero. A casual
inspection of the data suggests that players with these very high (or
very low) wOBAs were simply lucky (or unlucky). For example, the
4 players with the highest wOBAs each had fewer than 16 PAs. It is very
unlikely that they would have sustained this high level of production
over a full season's worth of PAs.

In contrast, Aaron Judge's production --- which included a
record-breaking number of home runs --- appears to be ``real,'' since
it was sustained over nearly 700 PAs.
% The National League and overall single-season record is held by
% Barry Bonds, who hit 73 home runs during the 2001 season.
% () 
Other cases are more ambiguous: how, for example, are we to assess
Matt Carpenter, who had several exceptional seasons between 2013 and
2018 but whose output steeply declined in 2019--2021 before his
surprising ``comeback'' in 2022? An empirical Bayes analysis can help
to answer this and other questions.

Function \code{ebnm()} is the main interface for fitting the empirical
Bayes normal means model (\ref{eqn:nm_problem}--\ref{eqn:nm_prior}); it is a
``Swiss army knife'' that allows for various choices of prior family
$\mathcal{G}$ as well as providing multiple options for fitting and tuning
models. For example, we can fit a normal means model with the prior family
$\mathcal{G}$ taken to be the family of normal distributions as follows:
\begin{CodeChunk}
\begin{CodeInput}
R> x <- wOBA$x
R> s <- wOBA$s
R> names(x) <- wOBA$Name
R> names(s) <- wOBA$Name
R> fit_normal <- ebnm(x, s, prior_family = "normal", mode = "estimate")
\end{CodeInput}
\end{CodeChunk}

(The default behavior is to fix the prior mode at zero.
% which yields a family of ``shrinkage priors,'' so-called because
% posterior means tend to be --- and, for families of symmetric
% distributions, are guaranteed to be --- nearer to zero than
% corresponding estimates.
Since we certainly do not expect the distribution of true wOBA
skill to have a mode at zero, we set \code{mode = "estimate"}.)

We note in passing that the \pkg{ebnm} package has a second model-fitting interface, in which
each prior family gets its own function:
\begin{CodeChunk}
\begin{CodeInput}
R> fit_normal <- ebnm_normal(x, s, mode = "estimate")
\end{CodeInput}
\end{CodeChunk}

Textual and graphical overviews of results can be obtained using, respectively, methods \code{summary()} and \code{plot()}. The summary method appears as follows:

\begin{CodeChunk}
\begin{CodeInput}
R> summary(fit_normal)
\end{CodeInput}
\begin{CodeOutput}
Call:
ebnm_normal(x = x, s = s, mode = "estimate")

EBNM model was fitted to 688 observations with _heteroskedastic_ standard 
errors.

The fitted prior belongs to the _normal_ prior family.

2 degrees of freedom were used to estimate the model.
The log likelihood is 989.64.

Available posterior summaries: _mean_, _sd_.
Use method fitted() to access available summaries.

A posterior sampler is _not_ available.
One can be added via function ebnm_add_sampler().
\end{CodeOutput}
\end{CodeChunk}

The \code{plot()} method visualizes results, comparing
the ``observed'' values $x_i$ (the initial wOBA estimates) against the
empirical Bayes posterior mean estimates $\hat{\theta}_i$:
\begin{CodeChunk}
\begin{CodeInput}
R> plot(fit_normal)
\end{CodeInput}
\end{CodeChunk}  

\begin{figure}[!t]
\centering
\includegraphics[width=0.8\textwidth]{figures/wOBA_normal.pdf}
\caption{Initial wOBA estimates (``observations'') vs. posterior mean
  wOBA estimates, in which the posterior estimates were obtained by
  fitting a prior from the family of normal distributions. The dashed
  line shows the diagonal $x = y$.}
% which makes it easier to assess the amount of shrinkage
% toward the mode that is being applied to each observation.
    \label{fig:wOBA_normal}
\end{figure}

See Figure~\ref{fig:wOBA_normal} for this plot. Shrinkage effects are clearly visible, with the most extreme
wOBAs on either end of the spectrum being strongly shrunk toward the league
average (around .300).

Since \code{plot()} returns a \code{"ggplot"} object \citep{ggplot2}, the
plot can conveniently be customized using \pkg{ggplot2} syntax. For example,
one can vary the color of the points by the number of plate
appearances:
\begin{CodeChunk}
\begin{CodeInput}
R> plot(fit_normal) +
+    geom_point(aes(color = sqrt(wOBA$PA))) +
+    labs(x = "wOBA", y = "EB estimate of true wOBA skill", 
+       color = expression(sqrt(PA))) +
+    scale_color_gradient(low = "blue", high = "red")
\end{CodeInput}
\end{CodeChunk}
See Figure~\ref{fig:wOBA_normal_custom} for this customized plot.
% Such plots are typical in the empirical Bayes literature: 
By varying the color of points, we see that the wOBA estimates with
higher standard errors or fewer plate appearances (blue points) tend
to be shrunk toward the league average much more strongly than wOBAs
from hitters with many plate appearances (red points).

\begin{figure}[!t]
\centering
\includegraphics[width=0.8\textwidth]{figures/wOBA_normal_custom.pdf}
\caption{The same as Figure~\protect\ref{fig:wOBA_normal}, except
  that the color of the points is varied by the number of plate
  appearances. The dashed line shows the diagonal ($x = y$) line.}
% The addition of color to the plot makes it clear that more shrinkage
% is being applied to observations with smaller sample sizes.
\label{fig:wOBA_normal_custom}
\end{figure}

Above, we used \code{head()} to view data for the first 6 hitters in the
data set. Let's now see what the EBNM analysis suggests might be their
``true'' wOBA skill. We use the
\code{fitted()} method, which returns a posterior summary for each
hitter:\footnote{By default, \code{fitted()} returns a posterior mean
  and posterior standard deviation, but other posterior information
  can be returned, including the {\em local false sign rate}
  \citep{Stephens_NewDeal}.}
\begin{CodeChunk}
\begin{CodeInput}    
> print(head(fitted(fit_normal)), digits = 3)
\end{CodeInput}
\begin{CodeOutput}
                mean     sd
Khalil Lee     0.303 0.0287
Chadwick Tromp 0.308 0.0286
Otto Lopez     0.310 0.0283
James Outman   0.311 0.0282
Matt Carpenter 0.339 0.0254
Aaron Judge    0.394 0.0184
\end{CodeOutput}
\end{CodeChunk}
The wOBA estimates of the first four ballplayers are shrunk strongly
toward the league average, reflecting the fact that these players had
very few plate appearances (and indeed, we were not swayed by their
very high initial wOBA estimates).

Carpenter had many more plate appearances (154) than these other
four players, but according to this model we should remain skeptical about
his strong performance; after factoring in the prior, we judge his
``true'' performance to be much closer to the league average,
downgrading an initial estimate of .472 to the final posterior mean
estimate of .339.

\begin{figure}[!t]
\centering
\includegraphics[width=0.8\textwidth]{figures/wOBA_comp.pdf}
\caption{Initial wOBA estimates (``Observations'') vs. posterior mean
  wOBA estimates, in which the posterior estimates were obtained by
  fitting a prior from the family of normal distributions
  (\code{prior\_family = "normal"}) and the family of unimodal
  distribtions (\code{prior\_family = "unimodal"}). Results are shown
  only for the top 50 ballplayers by number of plate appearances.}
\label{fig:wOBA_comp}
\end{figure}

Judge's ``true'' wOBA is also estimated to be much lower
(.394) than the initial estimate (.458) despite sustaining this high
level of production over a full season (696 PAs). For this reason, one
might ask whether a prior that is more flexible than the normal
prior---that is, a prior that can better adapt to ``outliers'' like
Judge---might produce a different result. The \pkg{ebnm} package
is very well suited to answering this question. For example, to
obtain results using a ``unimodal'' prior instead of a
normal prior, we need only change \code{prior_family} from
\code{"normal"} to \code{"unimodal"}:
\begin{CodeChunk}
\begin{CodeInput}
R> fit_unimodal <- ebnm(x, s, prior_family = "unimodal", mode = "estimate")
\end{CodeInput}
\end{CodeChunk}
It is straightforward to produce a side-by-side visualization of
the fitted models simply by including both models as arguments to the
\code{plot()} method:
\begin{CodeChunk}
\begin{CodeInput}
top50 <- order(wOBA$PA, decreasing = TRUE)
top50 <- top50[1:50]
plot(fit_normal, fit_unimodal, subset = top50)
\end{CodeInput}
\end{CodeChunk}
We also used the \code{subset} argument to focus on the results for
Judge and other players with the most plate appearances.  The plot
resulting from this call is shown in Figure~\ref{fig:wOBA_comp}. Indeed, this plot illustrates the ability of the
unimodal prior to better adapt to the data: wOBA estimates for players
with a lot of plate appearances are not adjusted quite so strongly
toward the league average. To compare in more detail, we see for
example that Judge's wOBA estimate from the model with the unimodal
prior (the \code{"mean2"} column) remains much closer to the original
wOBA estimate:
\begin{CodeChunk}
\begin{CodeInput}
R> dat <- cbind(wOBA[, c("PA","x")],
+               fitted(fit_normal),
+               fitted(fit_unimodal))
R> names(dat) <- c("PA", "x", "mean1", "sd1", "mean2", "sd2")
R> print(head(dat), digits = 3)
\end{CodeInput}
\begin{CodeOutput}
                PA     x mean1    sd1 mean2    sd2
Khalil Lee       2 1.036 0.303 0.0287 0.302 0.0277
Chadwick Tromp   4 0.852 0.308 0.0286 0.307 0.0306
Otto Lopez      10 0.599 0.310 0.0283 0.310 0.0315
James Outman    16 0.584 0.311 0.0282 0.311 0.0318
Matt Carpenter 154 0.472 0.339 0.0254 0.355 0.0430
Aaron Judge    696 0.458 0.394 0.0184 0.439 0.0155
\end{CodeOutput}
\end{CodeChunk}
Carpenter's wOBA estimate is also higher under the more flexible
unimodal prior, but is still adjusted much more than Judge's in light
of Carpenter's smaller sample size. It is also interesting that
the unimodal prior assigns greater uncertainty (the \code{"sd2"}
column) to this estimate compared to the normal prior.

\begin{figure}[!t]
\centering
\includegraphics[width=\textwidth]{figures/wOBA_comp_cdf.pdf}
\caption{The cumulative distribution functions (CDFs) for the priors
  that were fitted to the 2022 MLB wOBA data: the normal prior
  (\code{prior\_family = "normal"}) and the unimodal prior
  (\code{prior\_family = "unimodal"}). The right-hand panel shows the
  right tail of the priors in more detail.}
\label{fig:wOBA_comp_cdf}
\end{figure}

% At a glance, results appear similar across models for all but the
% highest and lowest wOBAs. As anticipated, far less shrinkage gets
% applied to very high wOBAs using the family of unimodal
% distributions. Additionally, low wOBAs appear to be shrunk toward a
% lower estimated mode.

Recall that the two normal means models differ only in the priors used, so
we can understand the differences in the shrinkage behavior of these
models by inspecting the priors. Calling \code{plot()} with
\code{incl_cdf = TRUE} shows the cumulative distribution functions
(CDFs) of the fitted priors $\hat{g}$. Since we are particularly
interested in understanding the differences in shrinkage behaviour for
the largest wOBAs such as Judge's, we create a second plot that zooms
in on wOBAs over .350:
\begin{CodeChunk}
\begin{CodeInput}
R> plot(fit_normal, fit_unimodal, incl_cdf = TRUE, incl_pm = FALSE) +
+    xlim(c(0.250, 0.450)) +
+    guides(color = "none")
R> plot(fit_normal, fit_unimodal, incl_cdf = TRUE, incl_pm = FALSE) +
+    xlim(c(0.350, 0.450)) +
+    ylim(c(0.95, 1))
\end{CodeInput}
\end{CodeChunk}
These plots are shown in Figure~\ref{fig:wOBA_comp_cdf}.  The plot on
the right shows that the fitted normal prior has almost no mass on
wOBAs above .400, explaining why Judge's wOBA estimate is shrunk
so strongly toward the league average, whereas the unimodal prior is
flexible enough to permit larger posterior estimates above .400.

% Further, the right tail for the (non-normal) unimodal prior
%  is substantially heavier: approximately 0.5\% of prior mass
% is above .400, while the normal prior $\hat{g}$ effectively puts zero
% mass in the same range. This difference in tails leads to the large
% difference in shrinkage behavior that we previously observed for high
% wOBAs.
% 
% As suspected, the mode estimated using the family of (asymmetric)
% unimodal priors is much lower than the mode estimated using the family
% of (symmetric) normal priors: the former is around .275 (with roughly
% 40\% of prior mass located at the mode), while the latter is near
% .300.

The posterior means and standard errors returned from the
\code{ebnm()} call cannot be used to obtain credible intervals
(except for the special case of the normal prior). Therefore, we
provide additional methods \code{confint()} and \code{quantile()}
which return, respectively, credible intervals (or more precisely,
{\em highest posterior density} intervals: \citealt{hpd, chen-1999})
and posterior quantiles for each observation. These are implemented
using Monte Carlo techniques, which can be slow for large data sets,
so credible intervals are not computed by default.  The
following code computes 80\% highest posterior density (HPD) intervals
for the EBNM model with unimodal prior. (We add a Monte Carlo sampler using function \code{ebnm_add_sampler()}; alternatively, we could have
added a sampler in our initial calls to \code{ebnm()} by
specifying \code{output = output_all()}.) We set a seed for
reproducibility:
\begin{CodeChunk}
\begin{CodeInput}
R> fit_unimodal <- ebnm_add_sampler(fit_unimodal)
R> set.seed(1)
R> print(head(confint(fit_unimodal, level = 0.8)), digits = 3)
\end{CodeInput}
\begin{CodeOutput}
               CI.lower CI.upper
Khalil Lee        0.277    0.328
Chadwick Tromp    0.277    0.334
Otto Lopez        0.277    0.336
James Outman      0.277    0.335
Matt Carpenter    0.277    0.389
Aaron Judge       0.428    0.458
\end{CodeOutput}
\end{CodeChunk}
Interestingly, the 80\% credible interval for Carpenter is very
wide, and shares the same lower bound as the first four ballplayers
with very few plate appearances.
